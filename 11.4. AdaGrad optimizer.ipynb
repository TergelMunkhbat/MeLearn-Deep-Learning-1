{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f9c01",
   "metadata": {},
   "source": [
    "# Deep Learning - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f7822",
   "metadata": {},
   "source": [
    "## Chapter 4: Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6d6e",
   "metadata": {},
   "source": [
    "### AdaGrad optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24843",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ca82",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca357a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a494e6",
   "metadata": {},
   "source": [
    "<img src=\"images/layer.png\" alt=\"Drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b879cc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e1ef8",
   "metadata": {},
   "source": [
    "#### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Linear:\n",
    "    \"\"\"Representing a neural network layer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"Initlize weights and bias\"\"\"\n",
    "        self.weights = np.random.randn(n_inputs, n_outputs)\n",
    "        self.biases = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        It multiplies the inputs by the weights \n",
    "        and then sums them, and then sums bias.\n",
    "        \"\"\"\n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        #Calculate outputs' values\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient with respect to parameters and input\"\"\"\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dresults = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a274b",
   "metadata": {},
   "source": [
    "#### Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe7222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dropout:\n",
    "    \"\"\"Representing a dropout layer\"\"\"\n",
    "    \n",
    "    def __init__(self, rate):\n",
    "        \"\"\"Initlize the success rate of binomial distribution\"\"\"\n",
    "        self.rate = 1 - rate\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Generate the scaled mask and then\n",
    "        apply the mask to the inputs values\n",
    "        \"\"\"\n",
    "        #Generate the scaled mask\n",
    "        self.scaled_mask = np.random.binomial(1, self.rate,\n",
    "                                             size=inputs.shape) / self.rate\n",
    "        #Calculate outputs' values\n",
    "        self.output = inputs * self.scaled_mask\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"\n",
    "        Gradient with respect to inputs, and then\n",
    "        multiply the dvalues accroding to the chain rule\n",
    "        \"\"\"\n",
    "        self.dresults = self.scaled_mask * dvalues    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103fd1",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c787f",
   "metadata": {},
   "source": [
    "#### Softmax Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d7786",
   "metadata": {},
   "source": [
    "<img src=\"images/softmax.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820a4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    \"\"\"Softmax activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #Compute e^x for each element of inputs\n",
    "        #Due to the overflow error, \n",
    "        #Maximum value of per sample subtract from each row\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                           keepdims=True))\n",
    "        \n",
    "        #Normalize them for each batch\n",
    "        self.output = exp_values / np.sum(exp_values, \n",
    "                                          axis=1, keepdims=True)\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient softmax\"\"\"\n",
    "        \n",
    "        #Initialize an array\n",
    "        self.dresults = np.zeros(dvalues.shape)\n",
    "        \n",
    "        for i in range(len(dvalues)):\n",
    "            #Reshape the single output\n",
    "            single_output = self.output[i].reshape(-1, 1)\n",
    "            \n",
    "            #Calculate Jacobian matrix of the single output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                                np.dot(single_output, single_output.T)\n",
    "            \n",
    "            #Multiply the Jacobian matrix by the loss function derivative\n",
    "            self.dresults[i] = np.dot(jacobian_matrix, dvalues[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e25066",
   "metadata": {},
   "source": [
    "#### ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    \"\"\"ReLU activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        #Calculate outputs' values\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Backward pass\"\"\"\n",
    "        \n",
    "        self.dresults = self.inputs > 0\n",
    "        self.dresults = self.dresults * dvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b26d3",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268858f",
   "metadata": {},
   "source": [
    "#### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5529a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MSE():\n",
    "    \"\"\"MSE Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"     \n",
    "        error = np.mean((y_pred - y_true) ** 2)\n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of MSE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        #Number of output nodes\n",
    "        outputs = len(y_pred[0])\n",
    "        \n",
    "        #Derivative of MSE\n",
    "        self.dresults = 2 * (y_pred - y_true) / (outputs * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e8970",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e2403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy():\n",
    "    \"\"\"Cross entropy Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        y_pred += 1e-10\n",
    "        y_pred = np.clip(y_pred, None, 1)\n",
    "        true_prediction = np.sum(y_pred * y_true, axis=1)\n",
    "        error = np.mean(-np.log(true_prediction)) \n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of CCE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = -y_true / (y_pred * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38650268",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy + Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24017a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy_Activation_SoftMax:\n",
    "    \"\"\"Cateogircal cross entropy loss and SoftMax function\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Softmax and CCE loss\"\"\"\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossEntropy()\n",
    "        \n",
    "    def forward(self, inputs, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        self.activation.forward(inputs)\n",
    "        return self.loss.forward(self.activation.output, y_true)\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Gradient of Categorical cross entropy + Softmax activation\"\"\"\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = (y_pred - y_true) / samples        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60fe79",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy_Categorical:\n",
    "    \"\"\"Accuracy calculation for classification\"\"\"\n",
    "    \n",
    "    def calculate(self, y_pred, y_true):\n",
    "        \"\"\"Calculate the accuracy\"\"\"\n",
    "        \n",
    "        true = np.argmax(y_true, axis=1)\n",
    "        pred = np.argmax(y_pred, axis=1)\n",
    "        comparisons = true == pred\n",
    "        \n",
    "        accuracy = np.mean(comparisons)\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d926f58",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a3dfc",
   "metadata": {},
   "source": [
    "#### Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1., momentum=0):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "\n",
    "        if self.momentum:\n",
    "            \n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            weights_delta = self.momentum * layer.weight_momentums + \\\n",
    "                            layer.dweights * self.alpha\n",
    "            biases_delta = self.momentum * layer.bias_momentums + \\\n",
    "                            layer.dbiases * self.alpha\n",
    "            \n",
    "            layer.weight_momentums = weights_delta\n",
    "            layer.bias_momentums = biases_delta\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            weights_delta = layer.dweights * self.alpha\n",
    "            biases_delta = layer.dbiases * self.alpha\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0940c",
   "metadata": {},
   "source": [
    "#### AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e71bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_AdaGrad:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1., epsilon=1e-10):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "            \n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weight_cache += layer.dweights ** 2\n",
    "        layer.bias_cache += layer.dbiases ** 2\n",
    "        \n",
    "        weights_delta = layer.dweights * self.alpha / \\\n",
    "                        (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        biases_delta =  layer.dbiases * self.alpha / \\\n",
    "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ba5dc",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912b52d",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Standard:\n",
    "    \"\"\"Standard scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find mean and std values\"\"\"\n",
    "        self.means = data.mean(axis=0)\n",
    "        self.stds = data.std(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.means) / self.stds\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c850cf2",
   "metadata": {},
   "source": [
    "#### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e5c1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_MinMax:\n",
    "    \"\"\"MinMax scaler\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_range=(0,1)):\n",
    "        \"\"\"Initialize the feature range\"\"\"\n",
    "        self.low, self.high = feature_range\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find min and max values\"\"\"\n",
    "        self.min = data.min(axis=0)\n",
    "        self.max = data.max(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        data_std = (data - self.min) / (self.max - self.min)\n",
    "        return data_std * (self.high - self.low) + self.low\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52189",
   "metadata": {},
   "source": [
    "#### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e867d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Robust:\n",
    "    \"\"\"Robust scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find median and iqr values\"\"\"\n",
    "        self.medians = np.median(data, axis=0)\n",
    "        self.p75, self.p25 = np.percentile(data, [75 ,25], axis=0)\n",
    "        self.iqr = self.p75 - self.p25\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.medians) / self.iqr\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c0507",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a12c",
   "metadata": {},
   "source": [
    "### Construct Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b843abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a14d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"\n",
    "    Load the MNIST fashion dataset\n",
    "    Convert the labels into one-hot vectors\n",
    "    \"\"\"\n",
    "\n",
    "    labels = os.listdir(os.path.join(path))\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for label in labels:\n",
    "        for file in os.listdir(os.path.join(path, label)):\n",
    "            image = cv2.imread(os.path.join(path, label, file),\n",
    "                                  cv2.IMREAD_UNCHANGED)\n",
    "            X.append(image)\n",
    "            Y.append(label)\n",
    "    \n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('uint8')\n",
    "    Y = np.eye(len(labels))[Y].astype('uint8')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b7862d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset, train_val_labels = load_dataset('../dataset/train')\n",
    "test_dataset, test_labels = load_dataset('../dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b886cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3d72",
   "metadata": {},
   "source": [
    "#### Flatten the every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cacffd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = train_val_dataset.reshape(len(train_val_dataset), -1)\n",
    "test_dataset = test_dataset.reshape(len(test_dataset), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d2ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516efe3",
   "metadata": {},
   "source": [
    "#### Data shuffling and splits to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d885db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.array(range(len(train_val_dataset)))\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "train_dataset = train_val_dataset[indexes[:50000]]\n",
    "train_labels = train_val_labels[indexes[:50000]]\n",
    "\n",
    "validation_dataset = train_val_dataset[indexes[50000:]]\n",
    "validation_labels = train_val_labels[indexes[50000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81da162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66358c0c",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1b2deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler_MinMax((-1,1))\n",
    "scaler.min = 0\n",
    "scaler.max = 255\n",
    "train_dataset = scaler.transform(train_dataset)\n",
    "test_dataset = scaler.transform(test_dataset)\n",
    "validation_dataset = scaler.transform(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef779a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145680b",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eabaef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 50\n",
    "alpha = 0.1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d0a1b",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c5ac970",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Linear(784, 128)\n",
    "activation1 = Activation_ReLU()\n",
    "dropout1 = Layer_Dropout(0.5)\n",
    "layer2 = Layer_Linear(128, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccf4b5",
   "metadata": {},
   "source": [
    "### Initlize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "329ded87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss_CategoricalCrossEntropy_Activation_SoftMax()\n",
    "accuracy = Accuracy_Categorical()\n",
    "optimizer = Optimizer_AdaGrad(alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c16f0",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e090a644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_steps = len(train_dataset) // batch_size\n",
    "if train_steps * batch_size < len(train_dataset):\n",
    "    train_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e0a9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_steps = len(validation_dataset) // batch_size\n",
    "if valid_steps * batch_size < len(validation_dataset):\n",
    "    valid_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bdc3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "###To track train and valid error\n",
    "train_error_history = []\n",
    "valid_error_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e6898c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train error: 2.695, Train accuracy: 0.420 Validation error: 1.222, Validation accuracy: 0.590\n",
      "epoch: 1, Train error: 1.524, Train accuracy: 0.456 Validation error: 1.076, Validation accuracy: 0.607\n",
      "epoch: 2, Train error: 1.377, Train accuracy: 0.483 Validation error: 0.972, Validation accuracy: 0.624\n",
      "epoch: 3, Train error: 1.305, Train accuracy: 0.502 Validation error: 0.945, Validation accuracy: 0.649\n",
      "epoch: 4, Train error: 1.234, Train accuracy: 0.522 Validation error: 0.888, Validation accuracy: 0.670\n",
      "epoch: 5, Train error: 1.198, Train accuracy: 0.530 Validation error: 0.871, Validation accuracy: 0.674\n",
      "epoch: 6, Train error: 1.158, Train accuracy: 0.541 Validation error: 0.850, Validation accuracy: 0.677\n",
      "epoch: 7, Train error: 1.127, Train accuracy: 0.548 Validation error: 0.851, Validation accuracy: 0.680\n",
      "epoch: 8, Train error: 1.110, Train accuracy: 0.558 Validation error: 0.815, Validation accuracy: 0.692\n",
      "epoch: 9, Train error: 1.087, Train accuracy: 0.560 Validation error: 0.807, Validation accuracy: 0.687\n",
      "epoch: 10, Train error: 1.081, Train accuracy: 0.564 Validation error: 0.816, Validation accuracy: 0.687\n",
      "epoch: 11, Train error: 1.056, Train accuracy: 0.571 Validation error: 0.791, Validation accuracy: 0.693\n",
      "epoch: 12, Train error: 1.046, Train accuracy: 0.573 Validation error: 0.788, Validation accuracy: 0.693\n",
      "epoch: 13, Train error: 1.032, Train accuracy: 0.575 Validation error: 0.775, Validation accuracy: 0.693\n",
      "epoch: 14, Train error: 1.018, Train accuracy: 0.579 Validation error: 0.768, Validation accuracy: 0.695\n",
      "epoch: 15, Train error: 1.010, Train accuracy: 0.583 Validation error: 0.769, Validation accuracy: 0.702\n",
      "epoch: 16, Train error: 1.002, Train accuracy: 0.586 Validation error: 0.764, Validation accuracy: 0.698\n",
      "epoch: 17, Train error: 0.991, Train accuracy: 0.587 Validation error: 0.760, Validation accuracy: 0.702\n",
      "epoch: 18, Train error: 0.984, Train accuracy: 0.595 Validation error: 0.757, Validation accuracy: 0.703\n",
      "epoch: 19, Train error: 0.976, Train accuracy: 0.596 Validation error: 0.744, Validation accuracy: 0.703\n",
      "epoch: 20, Train error: 0.974, Train accuracy: 0.596 Validation error: 0.755, Validation accuracy: 0.703\n",
      "epoch: 21, Train error: 0.955, Train accuracy: 0.602 Validation error: 0.743, Validation accuracy: 0.716\n",
      "epoch: 22, Train error: 0.945, Train accuracy: 0.606 Validation error: 0.733, Validation accuracy: 0.712\n",
      "epoch: 23, Train error: 0.941, Train accuracy: 0.610 Validation error: 0.730, Validation accuracy: 0.714\n",
      "epoch: 24, Train error: 0.934, Train accuracy: 0.614 Validation error: 0.727, Validation accuracy: 0.716\n",
      "epoch: 25, Train error: 0.929, Train accuracy: 0.616 Validation error: 0.717, Validation accuracy: 0.715\n",
      "epoch: 26, Train error: 0.919, Train accuracy: 0.623 Validation error: 0.713, Validation accuracy: 0.723\n",
      "epoch: 27, Train error: 0.916, Train accuracy: 0.628 Validation error: 0.712, Validation accuracy: 0.743\n",
      "epoch: 28, Train error: 0.908, Train accuracy: 0.631 Validation error: 0.701, Validation accuracy: 0.739\n",
      "epoch: 29, Train error: 0.894, Train accuracy: 0.637 Validation error: 0.701, Validation accuracy: 0.727\n",
      "epoch: 30, Train error: 0.891, Train accuracy: 0.638 Validation error: 0.690, Validation accuracy: 0.751\n",
      "epoch: 31, Train error: 0.889, Train accuracy: 0.641 Validation error: 0.695, Validation accuracy: 0.756\n",
      "epoch: 32, Train error: 0.882, Train accuracy: 0.642 Validation error: 0.688, Validation accuracy: 0.757\n",
      "epoch: 33, Train error: 0.874, Train accuracy: 0.646 Validation error: 0.687, Validation accuracy: 0.757\n",
      "epoch: 34, Train error: 0.873, Train accuracy: 0.645 Validation error: 0.685, Validation accuracy: 0.761\n",
      "epoch: 35, Train error: 0.866, Train accuracy: 0.648 Validation error: 0.682, Validation accuracy: 0.763\n",
      "epoch: 36, Train error: 0.869, Train accuracy: 0.649 Validation error: 0.677, Validation accuracy: 0.764\n",
      "epoch: 37, Train error: 0.865, Train accuracy: 0.647 Validation error: 0.675, Validation accuracy: 0.762\n",
      "epoch: 38, Train error: 0.854, Train accuracy: 0.654 Validation error: 0.682, Validation accuracy: 0.764\n",
      "epoch: 39, Train error: 0.857, Train accuracy: 0.651 Validation error: 0.667, Validation accuracy: 0.767\n",
      "epoch: 40, Train error: 0.846, Train accuracy: 0.656 Validation error: 0.677, Validation accuracy: 0.769\n",
      "epoch: 41, Train error: 0.840, Train accuracy: 0.658 Validation error: 0.666, Validation accuracy: 0.769\n",
      "epoch: 42, Train error: 0.840, Train accuracy: 0.660 Validation error: 0.663, Validation accuracy: 0.771\n",
      "epoch: 43, Train error: 0.834, Train accuracy: 0.660 Validation error: 0.668, Validation accuracy: 0.771\n",
      "epoch: 44, Train error: 0.832, Train accuracy: 0.662 Validation error: 0.659, Validation accuracy: 0.771\n",
      "epoch: 45, Train error: 0.830, Train accuracy: 0.662 Validation error: 0.665, Validation accuracy: 0.772\n",
      "epoch: 46, Train error: 0.830, Train accuracy: 0.666 Validation error: 0.664, Validation accuracy: 0.774\n",
      "epoch: 47, Train error: 0.828, Train accuracy: 0.666 Validation error: 0.653, Validation accuracy: 0.775\n",
      "epoch: 48, Train error: 0.819, Train accuracy: 0.669 Validation error: 0.647, Validation accuracy: 0.776\n",
      "epoch: 49, Train error: 0.823, Train accuracy: 0.666 Validation error: 0.650, Validation accuracy: 0.779\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_error = 0\n",
    "    valid_error = 0\n",
    "    train_accuracy = 0\n",
    "    valid_accuracy = 0\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = train_dataset[batch_start:batch_end]\n",
    "        true = train_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        dropout1.forward(activation1.output)\n",
    "        layer2.forward(dropout1.output)\n",
    "        train_error += loss.forward(layer2.output, true) / train_steps\n",
    "        train_accuracy += accuracy.calculate(layer2.output, true) / train_steps\n",
    "        \n",
    "        #Backward pass\n",
    "        loss.backward(loss.activation.output, true)\n",
    "        layer2.backward(loss.dresults)\n",
    "        dropout1.backward(layer2.dresults)\n",
    "        activation1.backward(dropout1.dresults)\n",
    "        layer1.backward(activation1.dresults)\n",
    "\n",
    "\n",
    "        optimizer.update_parameters(layer2)\n",
    "        optimizer.update_parameters(layer1)\n",
    "    \n",
    "    for i in range(valid_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = validation_dataset[batch_start:batch_end]\n",
    "        true = validation_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        valid_error += loss.forward(layer2.output, true) / valid_steps\n",
    "        valid_accuracy += accuracy.calculate(layer2.output, true) / valid_steps\n",
    "    \n",
    "    train_error_history.append(train_error)\n",
    "    valid_error_history.append(valid_error)\n",
    "    print(f'epoch: {epoch},',\n",
    "          f'Train error: {train_error:.3f},',\n",
    "          f'Train accuracy: {train_accuracy:.3f}',\n",
    "          f'Validation error: {valid_error:.3f},',\n",
    "          f'Validation accuracy: {valid_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e4f9e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d400018280>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_error_history, label='training error')\n",
    "plt.plot(valid_error_history, label='validation error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b236fa4",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3253f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = len(test_dataset) // batch_size\n",
    "if test_steps * batch_size < len(test_dataset):\n",
    "    test_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c60452",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "for i in range(test_steps):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = (i+1) * batch_size\n",
    "    \n",
    "    input = test_dataset[batch_start:batch_end]\n",
    "    true = test_labels[batch_start:batch_end]\n",
    "    \n",
    "    layer1.forward(input)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    test_error += loss.forward(layer2.output, true) / test_steps\n",
    "    test_accuracy += accuracy.calculate(layer2.output, true) / test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8902639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.704, Test accuracy: 0.769\n"
     ]
    }
   ],
   "source": [
    "print(f'Test error: {test_error:.3f},',\n",
    "      f'Test accuracy: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51997b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
