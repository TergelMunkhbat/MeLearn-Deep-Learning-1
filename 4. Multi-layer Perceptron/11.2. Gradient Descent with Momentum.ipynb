{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f9c01",
   "metadata": {},
   "source": [
    "# Deep Learning - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f7822",
   "metadata": {},
   "source": [
    "## Chapter 4: Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6d6e",
   "metadata": {},
   "source": [
    "### Gradient descent with Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24843",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ca82",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca357a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a494e6",
   "metadata": {},
   "source": [
    "<img src=\"images/layer.png\" alt=\"Drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b879cc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e1ef8",
   "metadata": {},
   "source": [
    "#### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Linear:\n",
    "    \"\"\"Representing a neural network layer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"Initlize weights and bias\"\"\"\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_outputs)\n",
    "        self.biases = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        It multiplies the inputs by the weights \n",
    "        and then sums them, and then sums bias.\n",
    "        \"\"\"\n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        #Calculate outputs' values\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient with respect to parameters and input\"\"\"\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dresults = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a274b",
   "metadata": {},
   "source": [
    "#### Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe7222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dropout:\n",
    "    \"\"\"Representing a dropout layer\"\"\"\n",
    "    \n",
    "    def __init__(self, rate):\n",
    "        \"\"\"Initlize the success rate of binomial distribution\"\"\"\n",
    "        self.rate = 1 - rate\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Generate the scaled mask and then\n",
    "        apply the mask to the inputs values\n",
    "        \"\"\"\n",
    "        #Generate the scaled mask\n",
    "        self.scaled_mask = np.random.binomial(1, self.rate,\n",
    "                                             size=inputs.shape) / self.rate\n",
    "        #Calculate outputs' values\n",
    "        self.output = inputs * self.scaled_mask\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"\n",
    "        Gradient with respect to inputs, and then\n",
    "        multiply the dvalues accroding to the chain rule\n",
    "        \"\"\"\n",
    "        self.dresults = self.scaled_mask * dvalues    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103fd1",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c787f",
   "metadata": {},
   "source": [
    "#### Softmax Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d7786",
   "metadata": {},
   "source": [
    "<img src=\"images/softmax.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820a4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    \"\"\"Softmax activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #Compute e^x for each element of inputs\n",
    "        #Due to the overflow error, \n",
    "        #Maximum value of per sample subtract from each row\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                           keepdims=True))\n",
    "        \n",
    "        #Normalize them for each batch\n",
    "        self.output = exp_values / np.sum(exp_values, \n",
    "                                          axis=1, keepdims=True)\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient softmax\"\"\"\n",
    "        \n",
    "        #Initialize an array\n",
    "        self.dresults = np.zeros(dvalues.shape)\n",
    "        \n",
    "        for i in range(len(dvalues)):\n",
    "            #Reshape the single output\n",
    "            single_output = self.output[i].reshape(-1, 1)\n",
    "            \n",
    "            #Calculate Jacobian matrix of the single output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                                np.dot(single_output, single_output.T)\n",
    "            \n",
    "            #Multiply the Jacobian matrix by the loss function derivative\n",
    "            self.dresults[i] = np.dot(jacobian_matrix, dvalues[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e25066",
   "metadata": {},
   "source": [
    "#### ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    \"\"\"ReLU activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        #Calculate outputs' values\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Backward pass\"\"\"\n",
    "        \n",
    "        self.dresults = self.inputs > 0\n",
    "        self.dresults = self.dresults * dvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b26d3",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268858f",
   "metadata": {},
   "source": [
    "#### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5529a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MSE():\n",
    "    \"\"\"MSE Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"     \n",
    "        error = np.mean((y_pred - y_true) ** 2)\n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of MSE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        #Number of output nodes\n",
    "        outputs = len(y_pred[0])\n",
    "        \n",
    "        #Derivative of MSE\n",
    "        self.dresults = 2 * (y_pred - y_true) / (outputs * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e8970",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e2403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy():\n",
    "    \"\"\"Cross entropy Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        y_pred += 1e-10\n",
    "        y_pred = np.clip(y_pred, None, 1)\n",
    "        true_prediction = np.sum(y_pred * y_true, axis=1)\n",
    "        error = np.mean(-np.log(true_prediction)) \n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of CCE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = -y_true / (y_pred * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38650268",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy + Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24017a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy_Activation_SoftMax:\n",
    "    \"\"\"Cateogircal cross entropy loss and SoftMax function\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Softmax and CCE loss\"\"\"\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossEntropy()\n",
    "        \n",
    "    def forward(self, inputs, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        self.activation.forward(inputs)\n",
    "        return self.loss.forward(self.activation.output, y_true)\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Gradient of Categorical cross entropy + Softmax activation\"\"\"\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = (y_pred - y_true) / samples        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60fe79",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy_Categorical:\n",
    "    \"\"\"Accuracy calculation for classification\"\"\"\n",
    "    \n",
    "    def calculate(self, y_pred, y_true):\n",
    "        \"\"\"Calculate the accuracy\"\"\"\n",
    "        \n",
    "        true = np.argmax(y_true, axis=1)\n",
    "        pred = np.argmax(y_pred, axis=1)\n",
    "        comparisons = true == pred\n",
    "        \n",
    "        accuracy = np.mean(comparisons)\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d926f58",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a3dfc",
   "metadata": {},
   "source": [
    "#### Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1., momentum=0):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "\n",
    "        if self.momentum:\n",
    "            \n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            weights_delta = self.momentum * layer.weight_momentums + \\\n",
    "                            layer.dweights * self.alpha\n",
    "            biases_delta = self.momentum * layer.bias_momentums + \\\n",
    "                            layer.dbiases * self.alpha\n",
    "            \n",
    "            layer.weight_momentums = weights_delta\n",
    "            layer.bias_momentums = biases_delta\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            weights_delta = layer.dweights * self.alpha\n",
    "            biases_delta = layer.dbiases * self.alpha\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ba5dc",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912b52d",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b97eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Standard:\n",
    "    \"\"\"Standard scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find mean and std values\"\"\"\n",
    "        self.means = data.mean(axis=0)\n",
    "        self.stds = data.std(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.means) / self.stds\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c850cf2",
   "metadata": {},
   "source": [
    "#### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5c1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_MinMax:\n",
    "    \"\"\"MinMax scaler\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_range=(0,1)):\n",
    "        \"\"\"Initialize the feature range\"\"\"\n",
    "        self.low, self.high = feature_range\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find min and max values\"\"\"\n",
    "        self.min = data.min(axis=0)\n",
    "        self.max = data.max(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        data_std = (data - self.min) / (self.max - self.min)\n",
    "        return data_std * (self.high - self.low) + self.low\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52189",
   "metadata": {},
   "source": [
    "#### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e867d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Robust:\n",
    "    \"\"\"Robust scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find median and iqr values\"\"\"\n",
    "        self.medians = np.median(data, axis=0)\n",
    "        self.p75, self.p25 = np.percentile(data, [75 ,25], axis=0)\n",
    "        self.iqr = self.p75 - self.p25\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.medians) / self.iqr\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c0507",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a12c",
   "metadata": {},
   "source": [
    "### Construct Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b843abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a14d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"\n",
    "    Load the MNIST fashion dataset\n",
    "    Convert the labels into one-hot vectors\n",
    "    \"\"\"\n",
    "\n",
    "    labels = os.listdir(os.path.join(path))\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for label in labels:\n",
    "        for file in os.listdir(os.path.join(path, label)):\n",
    "            image = cv2.imread(os.path.join(path, label, file),\n",
    "                                  cv2.IMREAD_UNCHANGED)\n",
    "            X.append(image)\n",
    "            Y.append(label)\n",
    "    \n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('uint8')\n",
    "    Y = np.eye(len(labels))[Y].astype('uint8')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b7862d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset, train_val_labels = load_dataset('../dataset/train')\n",
    "test_dataset, test_labels = load_dataset('../dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b886cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3d72",
   "metadata": {},
   "source": [
    "#### Flatten the every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacffd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = train_val_dataset.reshape(len(train_val_dataset), -1)\n",
    "test_dataset = test_dataset.reshape(len(test_dataset), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d2ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516efe3",
   "metadata": {},
   "source": [
    "#### Data shuffling and splits to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d885db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.array(range(len(train_val_dataset)))\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "train_dataset = train_val_dataset[indexes[:50000]]\n",
    "train_labels = train_val_labels[indexes[:50000]]\n",
    "\n",
    "validation_dataset = train_val_dataset[indexes[50000:]]\n",
    "validation_labels = train_val_labels[indexes[50000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81da162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66358c0c",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b2deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler_MinMax((-1,1))\n",
    "scaler.min = 0\n",
    "scaler.max = 255\n",
    "train_dataset = scaler.transform(train_dataset)\n",
    "test_dataset = scaler.transform(test_dataset)\n",
    "validation_dataset = scaler.transform(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eef779a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145680b",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eabaef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "alpha = 0.1\n",
    "batch_size = 128\n",
    "momentum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d0a1b",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c5ac970",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Linear(784, 128)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dropout1 = Layer_Dropout(0.25)\n",
    "\n",
    "layer2 = Layer_Linear(128, 64)\n",
    "activation2 = Activation_ReLU()\n",
    "\n",
    "layer3 = Layer_Linear(64, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccf4b5",
   "metadata": {},
   "source": [
    "### Initlize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "329ded87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss_CategoricalCrossEntropy_Activation_SoftMax()\n",
    "accuracy = Accuracy_Categorical()\n",
    "optimizer = Optimizer_GD(alpha=alpha, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c16f0",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e090a644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_steps = len(train_dataset) // batch_size\n",
    "if train_steps * batch_size < len(train_dataset):\n",
    "    train_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e0a9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_steps = len(validation_dataset) // batch_size\n",
    "if valid_steps * batch_size < len(validation_dataset):\n",
    "    valid_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bdc3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "###To track train and valid error\n",
    "train_error_history = []\n",
    "valid_error_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e6898c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train error: 1.376, Train accuracy: 0.467 Validation error: 1.059, Validation accuracy: 0.615\n",
      "epoch: 1, Train error: 0.611, Train accuracy: 0.774 Validation error: 0.499, Validation accuracy: 0.819\n",
      "epoch: 2, Train error: 0.500, Train accuracy: 0.817 Validation error: 0.430, Validation accuracy: 0.845\n",
      "epoch: 3, Train error: 0.451, Train accuracy: 0.836 Validation error: 0.399, Validation accuracy: 0.856\n",
      "epoch: 4, Train error: 0.421, Train accuracy: 0.846 Validation error: 0.375, Validation accuracy: 0.866\n",
      "epoch: 5, Train error: 0.398, Train accuracy: 0.855 Validation error: 0.361, Validation accuracy: 0.871\n",
      "epoch: 6, Train error: 0.381, Train accuracy: 0.862 Validation error: 0.359, Validation accuracy: 0.871\n",
      "epoch: 7, Train error: 0.368, Train accuracy: 0.867 Validation error: 0.343, Validation accuracy: 0.876\n",
      "epoch: 8, Train error: 0.357, Train accuracy: 0.869 Validation error: 0.344, Validation accuracy: 0.876\n",
      "epoch: 9, Train error: 0.346, Train accuracy: 0.874 Validation error: 0.342, Validation accuracy: 0.877\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_error = 0\n",
    "    valid_error = 0\n",
    "    train_accuracy = 0\n",
    "    valid_accuracy = 0\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = train_dataset[batch_start:batch_end]\n",
    "        true = train_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        dropout1.forward(activation1.output)\n",
    "        layer2.forward(dropout1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        layer3.forward(activation2.output)\n",
    "        \n",
    "        train_error += loss.forward(layer3.output, true) / train_steps\n",
    "        train_accuracy += accuracy.calculate(layer3.output, true) / train_steps\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward(loss.activation.output, true)\n",
    "        layer3.backward(loss.dresults)\n",
    "        activation2.backward(layer3.dresults)\n",
    "        layer2.backward(activation2.dresults)\n",
    "        dropout1.backward(layer2.dresults)\n",
    "        activation1.backward(dropout1.dresults)\n",
    "        layer1.backward(activation1.dresults)\n",
    "\n",
    "        #Update parameters\n",
    "        optimizer.update_parameters(layer3)\n",
    "        optimizer.update_parameters(layer2)\n",
    "        optimizer.update_parameters(layer1)\n",
    "    \n",
    "    for i in range(valid_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = validation_dataset[batch_start:batch_end]\n",
    "        true = validation_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        layer3.forward(activation2.output)\n",
    "        valid_error += loss.forward(layer3.output, true) / valid_steps\n",
    "        valid_accuracy += accuracy.calculate(layer3.output, true) / valid_steps\n",
    "    \n",
    "    train_error_history.append(train_error)\n",
    "    valid_error_history.append(valid_error)\n",
    "    print(f'epoch: {epoch},',\n",
    "          f'Train error: {train_error:.3f},',\n",
    "          f'Train accuracy: {train_accuracy:.3f}',\n",
    "          f'Validation error: {valid_error:.3f},',\n",
    "          f'Validation accuracy: {valid_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e4f9e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x157c4eb46a0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_error_history, label='training error')\n",
    "plt.plot(valid_error_history, label='validation error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b236fa4",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3253f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = len(test_dataset) // batch_size\n",
    "if test_steps * batch_size < len(test_dataset):\n",
    "    test_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66c60452",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "for i in range(test_steps):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = (i+1) * batch_size\n",
    "    \n",
    "    input = test_dataset[batch_start:batch_end]\n",
    "    true = test_labels[batch_start:batch_end]\n",
    "    \n",
    "    layer1.forward(input)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    layer3.forward(activation2.output)\n",
    "    test_error += loss.forward(layer3.output, true) / test_steps\n",
    "    test_accuracy += accuracy.calculate(layer3.output, true) / test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8902639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.380, Test accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "print(f'Test error: {test_error:.3f},',\n",
    "      f'Test accuracy: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052485e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error: 0.375, Test accuracy: 0.869\n",
    "# Test error: 0.367, Test accuracy: 0.873"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
