{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f9c01",
   "metadata": {},
   "source": [
    "# Deep Learning - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f7822",
   "metadata": {},
   "source": [
    "## Chapter 4: Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6d6e",
   "metadata": {},
   "source": [
    "### Gradient descent with Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24843",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ca82",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca357a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a494e6",
   "metadata": {},
   "source": [
    "<img src=\"images/layer.png\" alt=\"Drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b879cc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e1ef8",
   "metadata": {},
   "source": [
    "#### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Linear:\n",
    "    \"\"\"Representing a neural network layer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"Initlize weights and bias\"\"\"\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_outputs)\n",
    "        self.biases = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        It multiplies the inputs by the weights \n",
    "        and then sums them, and then sums bias.\n",
    "        \"\"\"\n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        #Calculate outputs' values\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient with respect to parameters and input\"\"\"\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dresults = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a274b",
   "metadata": {},
   "source": [
    "#### Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe7222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dropout:\n",
    "    \"\"\"Representing a dropout layer\"\"\"\n",
    "    \n",
    "    def __init__(self, rate):\n",
    "        \"\"\"Initlize the success rate of binomial distribution\"\"\"\n",
    "        self.rate = 1 - rate\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Generate the scaled mask and then\n",
    "        apply the mask to the inputs values\n",
    "        \"\"\"\n",
    "        #Generate the scaled mask\n",
    "        self.scaled_mask = np.random.binomial(1, self.rate,\n",
    "                                             size=inputs.shape) / self.rate\n",
    "        #Calculate outputs' values\n",
    "        self.output = inputs * self.scaled_mask\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"\n",
    "        Gradient with respect to inputs, and then\n",
    "        multiply the dvalues accroding to the chain rule\n",
    "        \"\"\"\n",
    "        self.dresults = self.scaled_mask * dvalues    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103fd1",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c787f",
   "metadata": {},
   "source": [
    "#### Softmax Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d7786",
   "metadata": {},
   "source": [
    "<img src=\"images/softmax.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820a4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    \"\"\"Softmax activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #Compute e^x for each element of inputs\n",
    "        #Due to the overflow error, \n",
    "        #Maximum value of per sample subtract from each row\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                           keepdims=True))\n",
    "        \n",
    "        #Normalize them for each batch\n",
    "        self.output = exp_values / np.sum(exp_values, \n",
    "                                          axis=1, keepdims=True)\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient softmax\"\"\"\n",
    "        \n",
    "        #Initialize an array\n",
    "        self.dresults = np.zeros(dvalues.shape)\n",
    "        \n",
    "        for i in range(len(dvalues)):\n",
    "            #Reshape the single output\n",
    "            single_output = self.output[i].reshape(-1, 1)\n",
    "            \n",
    "            #Calculate Jacobian matrix of the single output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                                np.dot(single_output, single_output.T)\n",
    "            \n",
    "            #Multiply the Jacobian matrix by the loss function derivative\n",
    "            self.dresults[i] = np.dot(jacobian_matrix, dvalues[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e25066",
   "metadata": {},
   "source": [
    "#### ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    \"\"\"ReLU activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        #Calculate outputs' values\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Backward pass\"\"\"\n",
    "        \n",
    "        self.dresults = self.inputs > 0\n",
    "        self.dresults = self.dresults * dvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b26d3",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268858f",
   "metadata": {},
   "source": [
    "#### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5529a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MSE():\n",
    "    \"\"\"MSE Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"     \n",
    "        error = np.mean((y_pred - y_true) ** 2)\n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of MSE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        #Number of output nodes\n",
    "        outputs = len(y_pred[0])\n",
    "        \n",
    "        #Derivative of MSE\n",
    "        self.dresults = 2 * (y_pred - y_true) / (outputs * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e8970",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e2403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy():\n",
    "    \"\"\"Cross entropy Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        y_pred += 1e-10\n",
    "        y_pred = np.clip(y_pred, None, 1)\n",
    "        true_prediction = np.sum(y_pred * y_true, axis=1)\n",
    "        error = np.mean(-np.log(true_prediction)) \n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of CCE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = -y_true / (y_pred * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38650268",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy + Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24017a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy_Activation_SoftMax:\n",
    "    \"\"\"Cateogircal cross entropy loss and SoftMax function\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Softmax and CCE loss\"\"\"\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossEntropy()\n",
    "        \n",
    "    def forward(self, inputs, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        self.activation.forward(inputs)\n",
    "        return self.loss.forward(self.activation.output, y_true)\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Gradient of Categorical cross entropy + Softmax activation\"\"\"\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = (y_pred - y_true) / samples        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60fe79",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy_Categorical:\n",
    "    \"\"\"Accuracy calculation for classification\"\"\"\n",
    "    \n",
    "    def calculate(self, y_pred, y_true):\n",
    "        \"\"\"Calculate the accuracy\"\"\"\n",
    "        \n",
    "        true = np.argmax(y_true, axis=1)\n",
    "        pred = np.argmax(y_pred, axis=1)\n",
    "        comparisons = true == pred\n",
    "        \n",
    "        accuracy = np.mean(comparisons)\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d926f58",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a3dfc",
   "metadata": {},
   "source": [
    "#### Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1., momentum=0):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "\n",
    "        if self.momentum:\n",
    "            \n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            weights_delta = self.momentum * layer.weight_momentums + \\\n",
    "                            layer.dweights * self.alpha\n",
    "            biases_delta = self.momentum * layer.bias_momentums + \\\n",
    "                            layer.dbiases * self.alpha\n",
    "            \n",
    "            layer.weight_momentums = weights_delta\n",
    "            layer.bias_momentums = biases_delta\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            weights_delta = layer.dweights * self.alpha\n",
    "            biases_delta = layer.dbiases * self.alpha\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dc2bc",
   "metadata": {},
   "source": [
    "#### AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0ed23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_AdaGrad:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1., epsilon=1e-10):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "            \n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weight_cache += layer.dweights ** 2\n",
    "        layer.bias_cache += layer.dbiases ** 2\n",
    "        \n",
    "        weights_delta = layer.dweights * self.alpha / \\\n",
    "                        (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        biases_delta =  layer.dbiases * self.alpha / \\\n",
    "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ba5dc",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912b52d",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b97eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Standard:\n",
    "    \"\"\"Standard scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find mean and std values\"\"\"\n",
    "        self.means = data.mean(axis=0)\n",
    "        self.stds = data.std(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.means) / self.stds\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c850cf2",
   "metadata": {},
   "source": [
    "#### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5c1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_MinMax:\n",
    "    \"\"\"MinMax scaler\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_range=(0,1)):\n",
    "        \"\"\"Initialize the feature range\"\"\"\n",
    "        self.low, self.high = feature_range\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find min and max values\"\"\"\n",
    "        self.min = data.min(axis=0)\n",
    "        self.max = data.max(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        data_std = (data - self.min) / (self.max - self.min)\n",
    "        return data_std * (self.high - self.low) + self.low\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52189",
   "metadata": {},
   "source": [
    "#### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e867d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Robust:\n",
    "    \"\"\"Robust scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find median and iqr values\"\"\"\n",
    "        self.medians = np.median(data, axis=0)\n",
    "        self.p75, self.p25 = np.percentile(data, [75 ,25], axis=0)\n",
    "        self.iqr = self.p75 - self.p25\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.medians) / self.iqr\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c0507",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a12c",
   "metadata": {},
   "source": [
    "### Construct Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b843abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a14d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"\n",
    "    Load the MNIST fashion dataset\n",
    "    Convert the labels into one-hot vectors\n",
    "    \"\"\"\n",
    "\n",
    "    labels = os.listdir(os.path.join(path))\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for label in labels:\n",
    "        for file in os.listdir(os.path.join(path, label)):\n",
    "            image = cv2.imread(os.path.join(path, label, file),\n",
    "                                  cv2.IMREAD_UNCHANGED)\n",
    "            X.append(image)\n",
    "            Y.append(label)\n",
    "    \n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('uint8')\n",
    "    Y = np.eye(len(labels))[Y].astype('uint8')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b7862d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset, train_val_labels = load_dataset('../dataset/train')\n",
    "test_dataset, test_labels = load_dataset('../dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b886cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3d72",
   "metadata": {},
   "source": [
    "#### Flatten the every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacffd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = train_val_dataset.reshape(len(train_val_dataset), -1)\n",
    "test_dataset = test_dataset.reshape(len(test_dataset), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d2ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516efe3",
   "metadata": {},
   "source": [
    "#### Data shuffling and splits to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d885db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.array(range(len(train_val_dataset)))\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "train_dataset = train_val_dataset[indexes[:50000]]\n",
    "train_labels = train_val_labels[indexes[:50000]]\n",
    "\n",
    "validation_dataset = train_val_dataset[indexes[50000:]]\n",
    "validation_labels = train_val_labels[indexes[50000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81da162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66358c0c",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b2deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler_MinMax((-1,1))\n",
    "scaler.min = 0\n",
    "scaler.max = 255\n",
    "train_dataset = scaler.transform(train_dataset)\n",
    "test_dataset = scaler.transform(test_dataset)\n",
    "validation_dataset = scaler.transform(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eef779a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145680b",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eabaef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "alpha = 0.1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d0a1b",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c5ac970",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Linear(784, 128)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dropout1 = Layer_Dropout(0.25)\n",
    "\n",
    "layer2 = Layer_Linear(128, 64)\n",
    "activation2 = Activation_ReLU()\n",
    "\n",
    "layer3 = Layer_Linear(64, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccf4b5",
   "metadata": {},
   "source": [
    "### Initlize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "329ded87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss_CategoricalCrossEntropy_Activation_SoftMax()\n",
    "accuracy = Accuracy_Categorical()\n",
    "optimizer = Optimizer_AdaGrad(alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c16f0",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e090a644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_steps = len(train_dataset) // batch_size\n",
    "if train_steps * batch_size < len(train_dataset):\n",
    "    train_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e0a9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_steps = len(validation_dataset) // batch_size\n",
    "if valid_steps * batch_size < len(validation_dataset):\n",
    "    valid_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bdc3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "###To track train and valid error\n",
    "train_error_history = []\n",
    "valid_error_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e6898c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train error: 1.016, Train accuracy: 0.682 Validation error: 0.523, Validation accuracy: 0.807\n",
      "epoch: 1, Train error: 0.581, Train accuracy: 0.787 Validation error: 0.462, Validation accuracy: 0.830\n",
      "epoch: 2, Train error: 0.518, Train accuracy: 0.811 Validation error: 0.433, Validation accuracy: 0.841\n",
      "epoch: 3, Train error: 0.488, Train accuracy: 0.821 Validation error: 0.412, Validation accuracy: 0.848\n",
      "epoch: 4, Train error: 0.463, Train accuracy: 0.831 Validation error: 0.411, Validation accuracy: 0.848\n",
      "epoch: 5, Train error: 0.450, Train accuracy: 0.834 Validation error: 0.411, Validation accuracy: 0.848\n",
      "epoch: 6, Train error: 0.436, Train accuracy: 0.840 Validation error: 0.391, Validation accuracy: 0.857\n",
      "epoch: 7, Train error: 0.426, Train accuracy: 0.844 Validation error: 0.386, Validation accuracy: 0.859\n",
      "epoch: 8, Train error: 0.411, Train accuracy: 0.849 Validation error: 0.380, Validation accuracy: 0.859\n",
      "epoch: 9, Train error: 0.408, Train accuracy: 0.851 Validation error: 0.371, Validation accuracy: 0.863\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_error = 0\n",
    "    valid_error = 0\n",
    "    train_accuracy = 0\n",
    "    valid_accuracy = 0\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = train_dataset[batch_start:batch_end]\n",
    "        true = train_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        dropout1.forward(activation1.output)\n",
    "        layer2.forward(dropout1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        layer3.forward(activation2.output)\n",
    "        \n",
    "        train_error += loss.forward(layer3.output, true) / train_steps\n",
    "        train_accuracy += accuracy.calculate(layer3.output, true) / train_steps\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward(loss.activation.output, true)\n",
    "        layer3.backward(loss.dresults)\n",
    "        activation2.backward(layer3.dresults)\n",
    "        layer2.backward(activation2.dresults)\n",
    "        dropout1.backward(layer2.dresults)\n",
    "        activation1.backward(dropout1.dresults)\n",
    "        layer1.backward(activation1.dresults)\n",
    "\n",
    "        #Update parameters\n",
    "        optimizer.update_parameters(layer3)\n",
    "        optimizer.update_parameters(layer2)\n",
    "        optimizer.update_parameters(layer1)\n",
    "    \n",
    "    for i in range(valid_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = validation_dataset[batch_start:batch_end]\n",
    "        true = validation_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        layer3.forward(activation2.output)\n",
    "        valid_error += loss.forward(layer3.output, true) / valid_steps\n",
    "        valid_accuracy += accuracy.calculate(layer3.output, true) / valid_steps\n",
    "    \n",
    "    train_error_history.append(train_error)\n",
    "    valid_error_history.append(valid_error)\n",
    "    print(f'epoch: {epoch},',\n",
    "          f'Train error: {train_error:.3f},',\n",
    "          f'Train accuracy: {train_accuracy:.3f}',\n",
    "          f'Validation error: {valid_error:.3f},',\n",
    "          f'Validation accuracy: {valid_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e4f9e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23faae8c670>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_error_history, label='training error')\n",
    "plt.plot(valid_error_history, label='validation error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b236fa4",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3253f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = len(test_dataset) // batch_size\n",
    "if test_steps * batch_size < len(test_dataset):\n",
    "    test_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66c60452",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "for i in range(test_steps):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = (i+1) * batch_size\n",
    "    \n",
    "    input = test_dataset[batch_start:batch_end]\n",
    "    true = test_labels[batch_start:batch_end]\n",
    "    \n",
    "    layer1.forward(input)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    layer3.forward(activation2.output)\n",
    "    test_error += loss.forward(layer3.output, true) / test_steps\n",
    "    test_accuracy += accuracy.calculate(layer3.output, true) / test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8902639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.396, Test accuracy: 0.859\n"
     ]
    }
   ],
   "source": [
    "print(f'Test error: {test_error:.3f},',\n",
    "      f'Test accuracy: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "052485e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GD(without momentum) Test error: 0.375, Test accuracy: 0.869\n",
    "# GD(with momentum)    Test error: 0.367, Test accuracy: 0.873"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
