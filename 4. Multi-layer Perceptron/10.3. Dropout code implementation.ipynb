{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f9c01",
   "metadata": {},
   "source": [
    "# Deep Learning - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f7822",
   "metadata": {},
   "source": [
    "## Chapter 4: Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6d6e",
   "metadata": {},
   "source": [
    "### Dropout derivative code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24843",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ca82",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca357a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a494e6",
   "metadata": {},
   "source": [
    "<img src=\"images/layer.png\" alt=\"Drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b879cc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e1ef8",
   "metadata": {},
   "source": [
    "#### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d55c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Linear:\n",
    "    \"\"\"Representing a neural network layer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"Initlize weights and bias\"\"\"\n",
    "        self.weights = np.random.randn(n_inputs, n_outputs)\n",
    "        self.biases = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        It multiplies the inputs by the weights \n",
    "        and then sums them, and then sums bias.\n",
    "        \"\"\"\n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        #Calculate outputs' values\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient with respect to parameters and input\"\"\"\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dresults = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a274b",
   "metadata": {},
   "source": [
    "#### Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe7222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dropout:\n",
    "    \"\"\"Representing a dropout layer\"\"\"\n",
    "    \n",
    "    def __init__(self, rate):\n",
    "        \"\"\"Initlize the success rate of binomial distribution\"\"\"\n",
    "        self.rate = 1 - rate\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Generate the scaled mask and then\n",
    "        apply the mask to the inputs values\n",
    "        \"\"\"\n",
    "        #Generate the scaled mask\n",
    "        self.scaled_mask = np.random.binomial(1, self.rate,\n",
    "                                             size=inputs.shape) / self.rate\n",
    "        #Calculate outputs' values\n",
    "        self.output = inputs * self.scaled_mask\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"\n",
    "        Gradient with respect to inputs, and then\n",
    "        multiply the dvalues accroding to the chain rule\n",
    "        \"\"\"\n",
    "        self.dresults = self.scaled_mask * dvalues    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34814655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 2., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_output = np.array([[1, 1, 1],\n",
    "                        [1, 1, 1]])\n",
    "dropout1 = Layer_Dropout(0.5)\n",
    "dropout1.forward(relu_output)\n",
    "dropout1.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103fd1",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c787f",
   "metadata": {},
   "source": [
    "#### Softmax Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d7786",
   "metadata": {},
   "source": [
    "<img src=\"images/softmax.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "820a4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    \"\"\"Softmax activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #Compute e^x for each element of inputs\n",
    "        #Due to the overflow error, \n",
    "        #Maximum value of per sample subtract from each row\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                           keepdims=True))\n",
    "        \n",
    "        #Normalize them for each batch\n",
    "        self.output = exp_values / np.sum(exp_values, \n",
    "                                          axis=1, keepdims=True)\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient softmax\"\"\"\n",
    "        \n",
    "        #Initialize an array\n",
    "        self.dresults = np.zeros(dvalues.shape)\n",
    "        \n",
    "        for i in range(len(dvalues)):\n",
    "            #Reshape the single output\n",
    "            single_output = self.output[i].reshape(-1, 1)\n",
    "            \n",
    "            #Calculate Jacobian matrix of the single output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                                np.dot(single_output, single_output.T)\n",
    "            \n",
    "            #Multiply the Jacobian matrix by the loss function derivative\n",
    "            self.dresults[i] = np.dot(jacobian_matrix, dvalues[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e25066",
   "metadata": {},
   "source": [
    "#### ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "000d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    \"\"\"ReLU activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        #Calculate outputs' values\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Backward pass\"\"\"\n",
    "        \n",
    "        self.dresults = self.inputs > 0\n",
    "        self.dresults = self.dresults * dvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b26d3",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268858f",
   "metadata": {},
   "source": [
    "#### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5529a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MSE():\n",
    "    \"\"\"MSE Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"     \n",
    "        error = np.mean((y_pred - y_true) ** 2)\n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of MSE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        #Number of output nodes\n",
    "        outputs = len(y_pred[0])\n",
    "        \n",
    "        #Derivative of MSE\n",
    "        self.dresults = 2 * (y_pred - y_true) / (outputs * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e8970",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07e2403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy():\n",
    "    \"\"\"Cross entropy Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        y_pred += 1e-10\n",
    "        y_pred = np.clip(y_pred, None, 1)\n",
    "        true_prediction = np.sum(y_pred * y_true, axis=1)\n",
    "        error = np.mean(-np.log(true_prediction)) \n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of CCE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = -y_true / (y_pred * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38650268",
   "metadata": {},
   "source": [
    "#### Categorical Cross-entropy + Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24017a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossEntropy_Activation_SoftMax:\n",
    "    \"\"\"Cateogircal cross entropy loss and SoftMax function\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Softmax and CCE loss\"\"\"\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossEntropy()\n",
    "        \n",
    "    def forward(self, inputs, y_true):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        self.activation.forward(inputs)\n",
    "        return self.loss.forward(self.activation.output, y_true)\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Gradient of Categorical cross entropy + Softmax activation\"\"\"\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        self.dresults = (y_pred - y_true) / samples        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60fe79",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e5b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy_Categorical:\n",
    "    \"\"\"Accuracy calculation for classification\"\"\"\n",
    "    \n",
    "    def calculate(self, y_pred, y_true):\n",
    "        \"\"\"Calculate the accuracy\"\"\"\n",
    "        \n",
    "        true = np.argmax(y_true, axis=1)\n",
    "        pred = np.argmax(y_pred, axis=1)\n",
    "        comparisons = true == pred\n",
    "        \n",
    "        accuracy = np.mean(comparisons)\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d926f58",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a3dfc",
   "metadata": {},
   "source": [
    "#### Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4d350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "        weights_delta = layer.dweights * self.alpha\n",
    "        biases_delta = layer.dbiases * self.alpha\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ba5dc",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912b52d",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b97eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Standard:\n",
    "    \"\"\"Standard scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find mean and std values\"\"\"\n",
    "        self.means = data.mean(axis=0)\n",
    "        self.stds = data.std(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.means) / self.stds\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c850cf2",
   "metadata": {},
   "source": [
    "#### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e5c1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_MinMax:\n",
    "    \"\"\"MinMax scaler\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_range=(0,1)):\n",
    "        \"\"\"Initialize the feature range\"\"\"\n",
    "        self.low, self.high = feature_range\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find min and max values\"\"\"\n",
    "        self.min = data.min(axis=0)\n",
    "        self.max = data.max(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        data_std = (data - self.min) / (self.max - self.min)\n",
    "        return data_std * (self.high - self.low) + self.low\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52189",
   "metadata": {},
   "source": [
    "#### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e867d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Robust:\n",
    "    \"\"\"Robust scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find median and iqr values\"\"\"\n",
    "        self.medians = np.median(data, axis=0)\n",
    "        self.p75, self.p25 = np.percentile(data, [75 ,25], axis=0)\n",
    "        self.iqr = self.p75 - self.p25\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.medians) / self.iqr\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c0507",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a12c",
   "metadata": {},
   "source": [
    "### Construct Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b843abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03a14d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"\n",
    "    Load the MNIST fashion dataset\n",
    "    Convert the labels into one-hot vectors\n",
    "    \"\"\"\n",
    "\n",
    "    labels = os.listdir(os.path.join(path))\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for label in labels:\n",
    "        for file in os.listdir(os.path.join(path, label)):\n",
    "            image = cv2.imread(os.path.join(path, label, file),\n",
    "                                  cv2.IMREAD_UNCHANGED)\n",
    "            X.append(image)\n",
    "            Y.append(label)\n",
    "    \n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).astype('uint8')\n",
    "    Y = np.eye(len(labels))[Y].astype('uint8')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b7862d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset, train_val_labels = load_dataset('../dataset/train')\n",
    "test_dataset, test_labels = load_dataset('../dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5b886cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3d72",
   "metadata": {},
   "source": [
    "#### Flatten the every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cacffd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = train_val_dataset.reshape(len(train_val_dataset), -1)\n",
    "test_dataset = test_dataset.reshape(len(test_dataset), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29d2ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516efe3",
   "metadata": {},
   "source": [
    "#### Data shuffling and splits to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d885db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.array(range(len(train_val_dataset)))\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "train_dataset = train_val_dataset[indexes[:50000]]\n",
    "train_labels = train_val_labels[indexes[:50000]]\n",
    "\n",
    "validation_dataset = train_val_dataset[indexes[50000:]]\n",
    "validation_labels = train_val_labels[indexes[50000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81da162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66358c0c",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1b2deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler_MinMax((-1,1))\n",
    "scaler.min = 0\n",
    "scaler.max = 255\n",
    "train_dataset = scaler.transform(train_dataset)\n",
    "test_dataset = scaler.transform(test_dataset)\n",
    "validation_dataset = scaler.transform(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eef779a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145680b",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eabaef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 70\n",
    "alpha = 0.1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d0a1b",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c5ac970",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer(784, 512)\n",
    "activation1 = Activation_ReLU()\n",
    "layer2 = Layer(512, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccf4b5",
   "metadata": {},
   "source": [
    "### Initlize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "329ded87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss_CategoricalCrossEntropy_Activation_SoftMax()\n",
    "accuracy = Accuracy_Categorical()\n",
    "optimizer = Optimizer_GD(alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c16f0",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e090a644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_steps = len(train_dataset) // batch_size\n",
    "if train_steps * batch_size < len(train_dataset):\n",
    "    train_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e0a9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_steps = len(validation_dataset) // batch_size\n",
    "if valid_steps * batch_size < len(validation_dataset):\n",
    "    valid_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5bdc3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "###To track train and valid error\n",
    "train_error_history = []\n",
    "valid_error_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e6898c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train error: 3.895, Train accuracy: 0.729 Validation error: 2.449, Validation accuracy: 0.745\n",
      "epoch: 1, Train error: 1.848, Train accuracy: 0.755 Validation error: 1.735, Validation accuracy: 0.748\n",
      "epoch: 2, Train error: 1.304, Train accuracy: 0.765 Validation error: 1.479, Validation accuracy: 0.749\n",
      "epoch: 3, Train error: 1.053, Train accuracy: 0.777 Validation error: 1.352, Validation accuracy: 0.759\n",
      "epoch: 4, Train error: 0.905, Train accuracy: 0.786 Validation error: 1.284, Validation accuracy: 0.765\n",
      "epoch: 5, Train error: 0.809, Train accuracy: 0.794 Validation error: 1.242, Validation accuracy: 0.770\n",
      "epoch: 6, Train error: 0.744, Train accuracy: 0.800 Validation error: 1.196, Validation accuracy: 0.775\n",
      "epoch: 7, Train error: 0.693, Train accuracy: 0.807 Validation error: 1.161, Validation accuracy: 0.779\n",
      "epoch: 8, Train error: 0.651, Train accuracy: 0.810 Validation error: 1.132, Validation accuracy: 0.780\n",
      "epoch: 9, Train error: 0.612, Train accuracy: 0.816 Validation error: 1.115, Validation accuracy: 0.783\n",
      "epoch: 10, Train error: 0.589, Train accuracy: 0.820 Validation error: 1.112, Validation accuracy: 0.783\n",
      "epoch: 11, Train error: 0.566, Train accuracy: 0.824 Validation error: 1.081, Validation accuracy: 0.786\n",
      "epoch: 12, Train error: 0.544, Train accuracy: 0.826 Validation error: 1.067, Validation accuracy: 0.786\n",
      "epoch: 13, Train error: 0.525, Train accuracy: 0.830 Validation error: 1.063, Validation accuracy: 0.788\n",
      "epoch: 14, Train error: 0.509, Train accuracy: 0.833 Validation error: 1.055, Validation accuracy: 0.790\n",
      "epoch: 15, Train error: 0.495, Train accuracy: 0.836 Validation error: 1.053, Validation accuracy: 0.790\n",
      "epoch: 16, Train error: 0.481, Train accuracy: 0.838 Validation error: 1.045, Validation accuracy: 0.793\n",
      "epoch: 17, Train error: 0.467, Train accuracy: 0.841 Validation error: 1.038, Validation accuracy: 0.794\n",
      "epoch: 18, Train error: 0.457, Train accuracy: 0.843 Validation error: 1.029, Validation accuracy: 0.794\n",
      "epoch: 19, Train error: 0.448, Train accuracy: 0.846 Validation error: 1.022, Validation accuracy: 0.797\n",
      "epoch: 20, Train error: 0.438, Train accuracy: 0.848 Validation error: 1.017, Validation accuracy: 0.797\n",
      "epoch: 21, Train error: 0.430, Train accuracy: 0.850 Validation error: 1.015, Validation accuracy: 0.798\n",
      "epoch: 22, Train error: 0.423, Train accuracy: 0.852 Validation error: 1.011, Validation accuracy: 0.797\n",
      "epoch: 23, Train error: 0.417, Train accuracy: 0.853 Validation error: 1.008, Validation accuracy: 0.798\n",
      "epoch: 24, Train error: 0.411, Train accuracy: 0.854 Validation error: 1.004, Validation accuracy: 0.799\n",
      "epoch: 25, Train error: 0.404, Train accuracy: 0.856 Validation error: 1.001, Validation accuracy: 0.799\n",
      "epoch: 26, Train error: 0.399, Train accuracy: 0.857 Validation error: 0.999, Validation accuracy: 0.798\n",
      "epoch: 27, Train error: 0.394, Train accuracy: 0.859 Validation error: 0.994, Validation accuracy: 0.799\n",
      "epoch: 28, Train error: 0.389, Train accuracy: 0.861 Validation error: 0.992, Validation accuracy: 0.799\n",
      "epoch: 29, Train error: 0.385, Train accuracy: 0.862 Validation error: 0.990, Validation accuracy: 0.799\n",
      "epoch: 30, Train error: 0.380, Train accuracy: 0.864 Validation error: 0.988, Validation accuracy: 0.800\n",
      "epoch: 31, Train error: 0.376, Train accuracy: 0.865 Validation error: 0.986, Validation accuracy: 0.799\n",
      "epoch: 32, Train error: 0.372, Train accuracy: 0.866 Validation error: 0.984, Validation accuracy: 0.799\n",
      "epoch: 33, Train error: 0.369, Train accuracy: 0.867 Validation error: 0.983, Validation accuracy: 0.801\n",
      "epoch: 34, Train error: 0.365, Train accuracy: 0.869 Validation error: 0.981, Validation accuracy: 0.801\n",
      "epoch: 35, Train error: 0.361, Train accuracy: 0.870 Validation error: 0.980, Validation accuracy: 0.800\n",
      "epoch: 36, Train error: 0.358, Train accuracy: 0.870 Validation error: 0.979, Validation accuracy: 0.801\n",
      "epoch: 37, Train error: 0.355, Train accuracy: 0.872 Validation error: 0.978, Validation accuracy: 0.801\n",
      "epoch: 38, Train error: 0.352, Train accuracy: 0.873 Validation error: 0.976, Validation accuracy: 0.802\n",
      "epoch: 39, Train error: 0.349, Train accuracy: 0.874 Validation error: 0.975, Validation accuracy: 0.802\n",
      "epoch: 40, Train error: 0.346, Train accuracy: 0.875 Validation error: 0.974, Validation accuracy: 0.803\n",
      "epoch: 41, Train error: 0.344, Train accuracy: 0.875 Validation error: 0.972, Validation accuracy: 0.803\n",
      "epoch: 42, Train error: 0.341, Train accuracy: 0.876 Validation error: 0.970, Validation accuracy: 0.804\n",
      "epoch: 43, Train error: 0.339, Train accuracy: 0.877 Validation error: 0.970, Validation accuracy: 0.805\n",
      "epoch: 44, Train error: 0.336, Train accuracy: 0.878 Validation error: 0.968, Validation accuracy: 0.805\n",
      "epoch: 45, Train error: 0.334, Train accuracy: 0.879 Validation error: 0.967, Validation accuracy: 0.806\n",
      "epoch: 46, Train error: 0.331, Train accuracy: 0.879 Validation error: 0.966, Validation accuracy: 0.806\n",
      "epoch: 47, Train error: 0.329, Train accuracy: 0.880 Validation error: 0.965, Validation accuracy: 0.805\n",
      "epoch: 48, Train error: 0.327, Train accuracy: 0.880 Validation error: 0.965, Validation accuracy: 0.805\n",
      "epoch: 49, Train error: 0.325, Train accuracy: 0.881 Validation error: 0.965, Validation accuracy: 0.806\n",
      "epoch: 50, Train error: 0.323, Train accuracy: 0.882 Validation error: 0.964, Validation accuracy: 0.806\n",
      "epoch: 51, Train error: 0.321, Train accuracy: 0.883 Validation error: 0.963, Validation accuracy: 0.807\n",
      "epoch: 52, Train error: 0.319, Train accuracy: 0.883 Validation error: 0.963, Validation accuracy: 0.806\n",
      "epoch: 53, Train error: 0.317, Train accuracy: 0.884 Validation error: 0.962, Validation accuracy: 0.807\n",
      "epoch: 54, Train error: 0.315, Train accuracy: 0.885 Validation error: 0.962, Validation accuracy: 0.808\n",
      "epoch: 55, Train error: 0.313, Train accuracy: 0.885 Validation error: 0.961, Validation accuracy: 0.808\n",
      "epoch: 56, Train error: 0.311, Train accuracy: 0.886 Validation error: 0.960, Validation accuracy: 0.808\n",
      "epoch: 57, Train error: 0.309, Train accuracy: 0.887 Validation error: 0.960, Validation accuracy: 0.809\n",
      "epoch: 58, Train error: 0.307, Train accuracy: 0.887 Validation error: 0.960, Validation accuracy: 0.809\n",
      "epoch: 59, Train error: 0.306, Train accuracy: 0.887 Validation error: 0.959, Validation accuracy: 0.810\n",
      "epoch: 60, Train error: 0.304, Train accuracy: 0.888 Validation error: 0.958, Validation accuracy: 0.810\n",
      "epoch: 61, Train error: 0.302, Train accuracy: 0.888 Validation error: 0.958, Validation accuracy: 0.811\n",
      "epoch: 62, Train error: 0.301, Train accuracy: 0.889 Validation error: 0.957, Validation accuracy: 0.811\n",
      "epoch: 63, Train error: 0.299, Train accuracy: 0.890 Validation error: 0.957, Validation accuracy: 0.812\n",
      "epoch: 64, Train error: 0.297, Train accuracy: 0.891 Validation error: 0.957, Validation accuracy: 0.813\n",
      "epoch: 65, Train error: 0.296, Train accuracy: 0.891 Validation error: 0.956, Validation accuracy: 0.812\n",
      "epoch: 66, Train error: 0.294, Train accuracy: 0.892 Validation error: 0.956, Validation accuracy: 0.812\n",
      "epoch: 67, Train error: 0.293, Train accuracy: 0.892 Validation error: 0.956, Validation accuracy: 0.813\n",
      "epoch: 68, Train error: 0.291, Train accuracy: 0.893 Validation error: 0.956, Validation accuracy: 0.813\n",
      "epoch: 69, Train error: 0.290, Train accuracy: 0.893 Validation error: 0.956, Validation accuracy: 0.813\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_error = 0\n",
    "    valid_error = 0\n",
    "    train_accuracy = 0\n",
    "    valid_accuracy = 0\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = train_dataset[batch_start:batch_end]\n",
    "        true = train_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        train_error += loss.forward(layer2.output, true) / train_steps\n",
    "        train_accuracy += accuracy.calculate(layer2.output, true) / train_steps\n",
    "        \n",
    "        #Backward pass\n",
    "        loss.backward(loss.activation.output, true)\n",
    "        layer2.backward(loss.dresults)\n",
    "        activation1.backward(layer2.dresults)\n",
    "        layer1.backward(activation1.dresults)\n",
    "\n",
    "\n",
    "        optimizer.update_parameters(layer2)\n",
    "        optimizer.update_parameters(layer1)\n",
    "    \n",
    "    for i in range(valid_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = validation_dataset[batch_start:batch_end]\n",
    "        true = validation_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        valid_error += loss.forward(layer2.output, true) / valid_steps\n",
    "        valid_accuracy += accuracy.calculate(layer2.output, true) / valid_steps\n",
    "    \n",
    "    train_error_history.append(train_error)\n",
    "    valid_error_history.append(valid_error)\n",
    "    print(f'epoch: {epoch},',\n",
    "          f'Train error: {train_error:.3f},',\n",
    "          f'Train accuracy: {train_accuracy:.3f}',\n",
    "          f'Validation error: {valid_error:.3f},',\n",
    "          f'Validation accuracy: {valid_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e4f9e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x275ab371790>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_error_history, label='training error')\n",
    "plt.plot(valid_error_history, label='validation error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b236fa4",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3253f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = len(test_dataset) // batch_size\n",
    "if test_steps * batch_size < len(test_dataset):\n",
    "    test_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66c60452",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "for i in range(test_steps):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = (i+1) * batch_size\n",
    "    \n",
    "    input = test_dataset[batch_start:batch_end]\n",
    "    true = test_labels[batch_start:batch_end]\n",
    "    \n",
    "    layer1.forward(input)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    test_error += loss.forward(layer2.output, true) / test_steps\n",
    "    test_accuracy += accuracy.calculate(layer2.output, true) / test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8902639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.997, Test accuracy: 0.803\n"
     ]
    }
   ],
   "source": [
    "print(f'Test error: {test_error:.3f},',\n",
    "      f'Test accuracy: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c8f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
