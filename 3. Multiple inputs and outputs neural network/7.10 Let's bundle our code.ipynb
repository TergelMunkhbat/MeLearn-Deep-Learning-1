{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f9c01",
   "metadata": {},
   "source": [
    "# Deep Learning - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f7822",
   "metadata": {},
   "source": [
    "## Chapter 3: Multiple inputs and outputs Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6d6e",
   "metadata": {},
   "source": [
    "### Let's bundle our code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24843",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ca82",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca357a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b879cc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e1ef8",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805bb49",
   "metadata": {},
   "source": [
    "<img src=\"images/layer.png\" alt=\"Drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"Representing a neural network layer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"Initlize weights and bias\"\"\"\n",
    "        #Mean=0 std = 1 68% -> [-1, 1]\n",
    "        self.weights = np.random.randn(n_inputs, n_outputs)\n",
    "        self.biases = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        It multiplies the inputs by the weights \n",
    "        and then sums them, and then sums bias.\n",
    "        \"\"\"\n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        #Calculate outputs' values\n",
    "        self.outputs = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient with respect to parameters\"\"\"\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b26d3",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268858f",
   "metadata": {},
   "source": [
    "#### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5529a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MSE:\n",
    "    \"\"\"MSE Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"     \n",
    "        error = np.mean((y_pred - y_true) ** 2)\n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of MSE with respect to pred\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        #Number of output nodes\n",
    "        outputs = len(y_pred[0])\n",
    "        \n",
    "        #Derivative of MSE\n",
    "        self.dresults = 2 * (y_pred - y_true) / (outputs * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d926f58",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a3dfc",
   "metadata": {},
   "source": [
    "#### Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "        weights_delta = layer.dweights * self.alpha\n",
    "        biases_delta = layer.dbiases * self.alpha\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ba5dc",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912b52d",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Standard:\n",
    "    \"\"\"Standard scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find mean and std values\"\"\"\n",
    "        self.means = data.mean(axis=0)\n",
    "        self.stds = data.std(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.means) / self.stds\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c850cf2",
   "metadata": {},
   "source": [
    "#### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5c1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_MinMax:\n",
    "    \"\"\"MinMax scaler\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_range=(0,1)):\n",
    "        \"\"\"Initialize the feature range\"\"\"\n",
    "        self.low, self.high = feature_range\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find min and max values\"\"\"\n",
    "        self.min = data.min(axis=0)\n",
    "        self.max = data.max(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        data_std = (data - self.min) / (self.max - self.min)\n",
    "        return data_std * (self.high - self.low) + self.low\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52189",
   "metadata": {},
   "source": [
    "#### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e867d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler_Robust:\n",
    "    \"\"\"Robust scaler\"\"\"\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Find median and iqr values\"\"\"\n",
    "        self.medians = np.median(data, axis=0)\n",
    "        self.p75, self.p25 = np.percentile(data, [75 ,25], axis=0)\n",
    "        self.iqr = self.p75 - self.p25\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforming data\"\"\"\n",
    "        return (data - self.medians) / self.iqr\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform data\"\"\"\n",
    "        return self.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c0507",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145680b",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabaef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 300\n",
    "alpha = 0.1\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a12c",
   "metadata": {},
   "source": [
    "### Construct Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abeb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array([[30, 2],  \n",
    "                          [25, 1],\n",
    "                          [27, 3],\n",
    "                          [23, 4]])\n",
    "train_label = np.array([[1],\n",
    "                        [2], \n",
    "                        [1], \n",
    "                        [3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66358c0c",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b2deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler_Standard()\n",
    "train_dataset = scaler.fit_transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd3cb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45010473, -0.4472136 ],\n",
       "       [-0.48336824, -1.34164079],\n",
       "       [ 0.29002095,  0.4472136 ],\n",
       "       [-1.25675744,  1.34164079]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d0a1b",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c5ac970",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccf4b5",
   "metadata": {},
   "source": [
    "### Initlize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "720bfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = Loss_MSE()\n",
    "optimizer = Optimizer_GD(alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c16f0",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e090a644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \tloss: 5.613878430332317\n",
      "epoch: 1 \tloss: 3.601833052442445\n",
      "epoch: 2 \tloss: 2.3640726671108765\n",
      "epoch: 3 \tloss: 1.5904103212725103\n",
      "epoch: 4 \tloss: 1.0991024409375743\n",
      "epoch: 5 \tloss: 0.7821853677929014\n",
      "epoch: 6 \tloss: 0.5746123255166299\n",
      "epoch: 7 \tloss: 0.4366297515071182\n",
      "epoch: 8 \tloss: 0.34359223187767873\n",
      "epoch: 9 \tloss: 0.280002255735254\n",
      "epoch: 10 \tloss: 0.23597721428765578\n",
      "epoch: 11 \tloss: 0.20512775218079168\n",
      "epoch: 12 \tloss: 0.18326697244884554\n",
      "epoch: 13 \tloss: 0.16761492519098095\n",
      "epoch: 14 \tloss: 0.1563020652976793\n",
      "epoch: 15 \tloss: 0.1480554299157472\n",
      "epoch: 16 \tloss: 0.14199785691985217\n",
      "epoch: 17 \tloss: 0.1375179753037586\n",
      "epoch: 18 \tloss: 0.13418502259727824\n",
      "epoch: 19 \tloss: 0.13169238085680252\n",
      "epoch: 20 \tloss: 0.12981971805366632\n",
      "epoch: 21 \tloss: 0.12840731653625578\n",
      "epoch: 22 \tloss: 0.1273384718892291\n",
      "epoch: 23 \tloss: 0.12652729420807043\n",
      "epoch: 24 \tloss: 0.12591016483856912\n",
      "epoch: 25 \tloss: 0.1254396929556683\n",
      "epoch: 26 \tloss: 0.12508039967841517\n",
      "epoch: 27 \tloss: 0.12480560829284186\n",
      "epoch: 28 \tloss: 0.1245951849254379\n",
      "epoch: 29 \tloss: 0.124433884606114\n",
      "epoch: 30 \tloss: 0.12431013216527936\n",
      "epoch: 31 \tloss: 0.12421511809566615\n",
      "epoch: 32 \tloss: 0.12414212433127311\n",
      "epoch: 33 \tloss: 0.1240860190538248\n",
      "epoch: 34 \tloss: 0.12404287655968817\n",
      "epoch: 35 \tloss: 0.12400969018654721\n",
      "epoch: 36 \tloss: 0.1239841548380387\n",
      "epoch: 37 \tloss: 0.12396450179055116\n",
      "epoch: 38 \tloss: 0.12394937292605988\n",
      "epoch: 39 \tloss: 0.12393772479528237\n",
      "epoch: 40 \tloss: 0.12392875531550185\n",
      "epoch: 41 \tloss: 0.12392184768514264\n",
      "epoch: 42 \tloss: 0.12391652742127938\n",
      "epoch: 43 \tloss: 0.12391242941732826\n",
      "epoch: 44 \tloss: 0.12390927266317026\n",
      "epoch: 45 \tloss: 0.12390684083208613\n",
      "epoch: 46 \tloss: 0.12390496736440752\n",
      "epoch: 47 \tloss: 0.1239035240007986\n",
      "epoch: 48 \tloss: 0.12390241196386512\n",
      "epoch: 49 \tloss: 0.123901555174177\n",
      "epoch: 50 \tloss: 0.1239008950299143\n",
      "epoch: 51 \tloss: 0.12390038638881097\n",
      "epoch: 52 \tloss: 0.12389999447490026\n",
      "epoch: 53 \tloss: 0.1238996924968274\n",
      "epoch: 54 \tloss: 0.12389945981379667\n",
      "epoch: 55 \tloss: 0.12389928052307608\n",
      "epoch: 56 \tloss: 0.12389914237206498\n",
      "epoch: 57 \tloss: 0.12389903592028119\n",
      "epoch: 58 \tloss: 0.1238989538938163\n",
      "epoch: 59 \tloss: 0.12389889068802779\n",
      "epoch: 60 \tloss: 0.12389884198441076\n",
      "epoch: 61 \tloss: 0.12389880445542545\n",
      "epoch: 62 \tloss: 0.12389877553707823\n",
      "epoch: 63 \tloss: 0.12389875325370323\n",
      "epoch: 64 \tloss: 0.12389873608295619\n",
      "epoch: 65 \tloss: 0.12389872285179376\n",
      "epoch: 66 \tloss: 0.1238987126563225\n",
      "epoch: 67 \tloss: 0.12389870480004131\n",
      "epoch: 68 \tloss: 0.12389869874625516\n",
      "epoch: 69 \tloss: 0.12389869408140805\n",
      "epoch: 70 \tloss: 0.12389869048682954\n",
      "epoch: 71 \tloss: 0.12389868771696357\n",
      "epoch: 72 \tloss: 0.12389868558259376\n",
      "epoch: 73 \tloss: 0.12389868393791628\n",
      "epoch: 74 \tloss: 0.12389868267057996\n",
      "epoch: 75 \tloss: 0.12389868169401036\n",
      "epoch: 76 \tloss: 0.12389868094149648\n",
      "epoch: 77 \tloss: 0.12389868036163279\n",
      "epoch: 78 \tloss: 0.12389867991480788\n",
      "epoch: 79 \tloss: 0.12389867957049842\n",
      "epoch: 80 \tloss: 0.1238986793051843\n",
      "epoch: 81 \tloss: 0.12389867910074145\n",
      "epoch: 82 \tloss: 0.12389867894320403\n",
      "epoch: 83 \tloss: 0.1238986788218106\n",
      "epoch: 84 \tloss: 0.12389867872826854\n",
      "epoch: 85 \tloss: 0.12389867865618796\n",
      "epoch: 86 \tloss: 0.12389867860064484\n",
      "epoch: 87 \tloss: 0.12389867855784495\n",
      "epoch: 88 \tloss: 0.12389867852486483\n",
      "epoch: 89 \tloss: 0.12389867849945123\n",
      "epoch: 90 \tloss: 0.12389867847986835\n",
      "epoch: 91 \tloss: 0.12389867846477837\n",
      "epoch: 92 \tloss: 0.12389867845315053\n",
      "epoch: 93 \tloss: 0.1238986784441904\n",
      "epoch: 94 \tloss: 0.123898678437286\n",
      "epoch: 95 \tloss: 0.12389867843196577\n",
      "epoch: 96 \tloss: 0.12389867842786603\n",
      "epoch: 97 \tloss: 0.12389867842470702\n",
      "epoch: 98 \tloss: 0.12389867842227274\n",
      "epoch: 99 \tloss: 0.12389867842039697\n",
      "epoch: 100 \tloss: 0.12389867841895155\n",
      "epoch: 101 \tloss: 0.12389867841783778\n",
      "epoch: 102 \tloss: 0.12389867841697952\n",
      "epoch: 103 \tloss: 0.12389867841631813\n",
      "epoch: 104 \tloss: 0.12389867841580847\n",
      "epoch: 105 \tloss: 0.12389867841541585\n",
      "epoch: 106 \tloss: 0.12389867841511328\n",
      "epoch: 107 \tloss: 0.12389867841488003\n",
      "epoch: 108 \tloss: 0.1238986784147004\n",
      "epoch: 109 \tloss: 0.12389867841456197\n",
      "epoch: 110 \tloss: 0.12389867841445523\n",
      "epoch: 111 \tloss: 0.12389867841437302\n",
      "epoch: 112 \tloss: 0.12389867841430965\n",
      "epoch: 113 \tloss: 0.12389867841426086\n",
      "epoch: 114 \tloss: 0.1238986784142233\n",
      "epoch: 115 \tloss: 0.12389867841419425\n",
      "epoch: 116 \tloss: 0.12389867841417199\n",
      "epoch: 117 \tloss: 0.12389867841415472\n",
      "epoch: 118 \tloss: 0.12389867841414148\n",
      "epoch: 119 \tloss: 0.12389867841413127\n",
      "epoch: 120 \tloss: 0.12389867841412341\n",
      "epoch: 121 \tloss: 0.12389867841411731\n",
      "epoch: 122 \tloss: 0.1238986784141126\n",
      "epoch: 123 \tloss: 0.12389867841410901\n",
      "epoch: 124 \tloss: 0.1238986784141062\n",
      "epoch: 125 \tloss: 0.1238986784141041\n",
      "epoch: 126 \tloss: 0.12389867841410244\n",
      "epoch: 127 \tloss: 0.12389867841410122\n",
      "epoch: 128 \tloss: 0.12389867841410018\n",
      "epoch: 129 \tloss: 0.12389867841409948\n",
      "epoch: 130 \tloss: 0.12389867841409893\n",
      "epoch: 131 \tloss: 0.12389867841409845\n",
      "epoch: 132 \tloss: 0.12389867841409814\n",
      "epoch: 133 \tloss: 0.12389867841409785\n",
      "epoch: 134 \tloss: 0.12389867841409763\n",
      "epoch: 135 \tloss: 0.12389867841409745\n",
      "epoch: 136 \tloss: 0.1238986784140974\n",
      "epoch: 137 \tloss: 0.12389867841409724\n",
      "epoch: 138 \tloss: 0.12389867841409723\n",
      "epoch: 139 \tloss: 0.12389867841409713\n",
      "epoch: 140 \tloss: 0.12389867841409707\n",
      "epoch: 141 \tloss: 0.123898678414097\n",
      "epoch: 142 \tloss: 0.12389867841409702\n",
      "epoch: 143 \tloss: 0.123898678414097\n",
      "epoch: 144 \tloss: 0.12389867841409698\n",
      "epoch: 145 \tloss: 0.12389867841409699\n",
      "epoch: 146 \tloss: 0.12389867841409699\n",
      "epoch: 147 \tloss: 0.12389867841409699\n",
      "epoch: 148 \tloss: 0.12389867841409696\n",
      "epoch: 149 \tloss: 0.12389867841409688\n",
      "epoch: 150 \tloss: 0.12389867841409687\n",
      "epoch: 151 \tloss: 0.12389867841409688\n",
      "epoch: 152 \tloss: 0.12389867841409691\n",
      "epoch: 153 \tloss: 0.12389867841409691\n",
      "epoch: 154 \tloss: 0.12389867841409694\n",
      "epoch: 155 \tloss: 0.12389867841409691\n",
      "epoch: 156 \tloss: 0.12389867841409699\n",
      "epoch: 157 \tloss: 0.12389867841409695\n",
      "epoch: 158 \tloss: 0.12389867841409694\n",
      "epoch: 159 \tloss: 0.12389867841409692\n",
      "epoch: 160 \tloss: 0.12389867841409699\n",
      "epoch: 161 \tloss: 0.12389867841409696\n",
      "epoch: 162 \tloss: 0.12389867841409691\n",
      "epoch: 163 \tloss: 0.12389867841409694\n",
      "epoch: 164 \tloss: 0.12389867841409695\n",
      "epoch: 165 \tloss: 0.12389867841409695\n",
      "epoch: 166 \tloss: 0.12389867841409691\n",
      "epoch: 167 \tloss: 0.12389867841409694\n",
      "epoch: 168 \tloss: 0.1238986784140969\n",
      "epoch: 169 \tloss: 0.12389867841409695\n",
      "epoch: 170 \tloss: 0.12389867841409696\n",
      "epoch: 171 \tloss: 0.12389867841409694\n",
      "epoch: 172 \tloss: 0.12389867841409691\n",
      "epoch: 173 \tloss: 0.12389867841409692\n",
      "epoch: 174 \tloss: 0.12389867841409699\n",
      "epoch: 175 \tloss: 0.12389867841409694\n",
      "epoch: 176 \tloss: 0.12389867841409691\n",
      "epoch: 177 \tloss: 0.12389867841409694\n",
      "epoch: 178 \tloss: 0.12389867841409698\n",
      "epoch: 179 \tloss: 0.12389867841409694\n",
      "epoch: 180 \tloss: 0.12389867841409698\n",
      "epoch: 181 \tloss: 0.12389867841409694\n",
      "epoch: 182 \tloss: 0.12389867841409688\n",
      "epoch: 183 \tloss: 0.12389867841409698\n",
      "epoch: 184 \tloss: 0.12389867841409694\n",
      "epoch: 185 \tloss: 0.12389867841409698\n",
      "epoch: 186 \tloss: 0.12389867841409696\n",
      "epoch: 187 \tloss: 0.12389867841409691\n",
      "epoch: 188 \tloss: 0.123898678414097\n",
      "epoch: 189 \tloss: 0.12389867841409692\n",
      "epoch: 190 \tloss: 0.1238986784140969\n",
      "epoch: 191 \tloss: 0.12389867841409694\n",
      "epoch: 192 \tloss: 0.12389867841409695\n",
      "epoch: 193 \tloss: 0.12389867841409691\n",
      "epoch: 194 \tloss: 0.12389867841409694\n",
      "epoch: 195 \tloss: 0.12389867841409699\n",
      "epoch: 196 \tloss: 0.12389867841409691\n",
      "epoch: 197 \tloss: 0.12389867841409695\n",
      "epoch: 198 \tloss: 0.12389867841409696\n",
      "epoch: 199 \tloss: 0.12389867841409691\n",
      "epoch: 200 \tloss: 0.12389867841409688\n",
      "epoch: 201 \tloss: 0.12389867841409696\n",
      "epoch: 202 \tloss: 0.12389867841409695\n",
      "epoch: 203 \tloss: 0.12389867841409692\n",
      "epoch: 204 \tloss: 0.1238986784140969\n",
      "epoch: 205 \tloss: 0.12389867841409695\n",
      "epoch: 206 \tloss: 0.12389867841409687\n",
      "epoch: 207 \tloss: 0.12389867841409696\n",
      "epoch: 208 \tloss: 0.12389867841409687\n",
      "epoch: 209 \tloss: 0.12389867841409698\n",
      "epoch: 210 \tloss: 0.12389867841409694\n",
      "epoch: 211 \tloss: 0.12389867841409694\n",
      "epoch: 212 \tloss: 0.12389867841409694\n",
      "epoch: 213 \tloss: 0.12389867841409698\n",
      "epoch: 214 \tloss: 0.12389867841409695\n",
      "epoch: 215 \tloss: 0.12389867841409691\n",
      "epoch: 216 \tloss: 0.12389867841409692\n",
      "epoch: 217 \tloss: 0.12389867841409699\n",
      "epoch: 218 \tloss: 0.12389867841409691\n",
      "epoch: 219 \tloss: 0.12389867841409696\n",
      "epoch: 220 \tloss: 0.12389867841409696\n",
      "epoch: 221 \tloss: 0.12389867841409688\n",
      "epoch: 222 \tloss: 0.12389867841409691\n",
      "epoch: 223 \tloss: 0.12389867841409691\n",
      "epoch: 224 \tloss: 0.1238986784140969\n",
      "epoch: 225 \tloss: 0.12389867841409688\n",
      "epoch: 226 \tloss: 0.12389867841409691\n",
      "epoch: 227 \tloss: 0.12389867841409694\n",
      "epoch: 228 \tloss: 0.12389867841409694\n",
      "epoch: 229 \tloss: 0.12389867841409694\n",
      "epoch: 230 \tloss: 0.12389867841409691\n",
      "epoch: 231 \tloss: 0.12389867841409698\n",
      "epoch: 232 \tloss: 0.12389867841409698\n",
      "epoch: 233 \tloss: 0.12389867841409692\n",
      "epoch: 234 \tloss: 0.12389867841409692\n",
      "epoch: 235 \tloss: 0.12389867841409694\n",
      "epoch: 236 \tloss: 0.12389867841409694\n",
      "epoch: 237 \tloss: 0.12389867841409694\n",
      "epoch: 238 \tloss: 0.12389867841409695\n",
      "epoch: 239 \tloss: 0.12389867841409696\n",
      "epoch: 240 \tloss: 0.12389867841409694\n",
      "epoch: 241 \tloss: 0.1238986784140969\n",
      "epoch: 242 \tloss: 0.12389867841409695\n",
      "epoch: 243 \tloss: 0.12389867841409691\n",
      "epoch: 244 \tloss: 0.12389867841409691\n",
      "epoch: 245 \tloss: 0.12389867841409698\n",
      "epoch: 246 \tloss: 0.12389867841409694\n",
      "epoch: 247 \tloss: 0.12389867841409687\n",
      "epoch: 248 \tloss: 0.12389867841409694\n",
      "epoch: 249 \tloss: 0.12389867841409696\n",
      "epoch: 250 \tloss: 0.1238986784140969\n",
      "epoch: 251 \tloss: 0.12389867841409695\n",
      "epoch: 252 \tloss: 0.12389867841409688\n",
      "epoch: 253 \tloss: 0.12389867841409694\n",
      "epoch: 254 \tloss: 0.12389867841409692\n",
      "epoch: 255 \tloss: 0.12389867841409696\n",
      "epoch: 256 \tloss: 0.12389867841409692\n",
      "epoch: 257 \tloss: 0.12389867841409691\n",
      "epoch: 258 \tloss: 0.12389867841409692\n",
      "epoch: 259 \tloss: 0.12389867841409691\n",
      "epoch: 260 \tloss: 0.12389867841409696\n",
      "epoch: 261 \tloss: 0.12389867841409695\n",
      "epoch: 262 \tloss: 0.123898678414097\n",
      "epoch: 263 \tloss: 0.12389867841409691\n",
      "epoch: 264 \tloss: 0.12389867841409691\n",
      "epoch: 265 \tloss: 0.12389867841409698\n",
      "epoch: 266 \tloss: 0.12389867841409694\n",
      "epoch: 267 \tloss: 0.12389867841409694\n",
      "epoch: 268 \tloss: 0.12389867841409691\n",
      "epoch: 269 \tloss: 0.12389867841409691\n",
      "epoch: 270 \tloss: 0.12389867841409695\n",
      "epoch: 271 \tloss: 0.12389867841409698\n",
      "epoch: 272 \tloss: 0.12389867841409691\n",
      "epoch: 273 \tloss: 0.12389867841409698\n",
      "epoch: 274 \tloss: 0.12389867841409691\n",
      "epoch: 275 \tloss: 0.12389867841409691\n",
      "epoch: 276 \tloss: 0.12389867841409691\n",
      "epoch: 277 \tloss: 0.12389867841409691\n",
      "epoch: 278 \tloss: 0.12389867841409691\n",
      "epoch: 279 \tloss: 0.12389867841409691\n",
      "epoch: 280 \tloss: 0.12389867841409691\n",
      "epoch: 281 \tloss: 0.12389867841409691\n",
      "epoch: 282 \tloss: 0.12389867841409691\n",
      "epoch: 283 \tloss: 0.12389867841409691\n",
      "epoch: 284 \tloss: 0.12389867841409691\n",
      "epoch: 285 \tloss: 0.12389867841409691\n",
      "epoch: 286 \tloss: 0.12389867841409696\n",
      "epoch: 287 \tloss: 0.12389867841409696\n",
      "epoch: 288 \tloss: 0.12389867841409696\n",
      "epoch: 289 \tloss: 0.12389867841409696\n",
      "epoch: 290 \tloss: 0.12389867841409696\n",
      "epoch: 291 \tloss: 0.12389867841409696\n",
      "epoch: 292 \tloss: 0.12389867841409696\n",
      "epoch: 293 \tloss: 0.12389867841409696\n",
      "epoch: 294 \tloss: 0.12389867841409696\n",
      "epoch: 295 \tloss: 0.12389867841409696\n",
      "epoch: 296 \tloss: 0.12389867841409696\n",
      "epoch: 297 \tloss: 0.12389867841409696\n",
      "epoch: 298 \tloss: 0.12389867841409696\n",
      "epoch: 299 \tloss: 0.12389867841409696\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    #Forward pass\n",
    "    layer1.forward(train_dataset)\n",
    "    loss = loss_function.forward(layer1.outputs, train_label)\n",
    "    print(f'epoch: {epoch} \\tloss: {loss}')\n",
    "    \n",
    "    #Backward pass\n",
    "    loss_function.backward(layer1.outputs, train_label)\n",
    "    layer1.backward(loss_function.dresults)\n",
    "    \n",
    "    #Update parameters\n",
    "    optimizer.update_parameters(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f39efd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72909818],\n",
       "       [ 0.05171523]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dcc5428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.75]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd113c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
